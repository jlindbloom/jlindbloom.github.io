<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.577">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-07-12">
<meta name="description" content="Hierarchical regularization via an auxiliary variable magic trick.">

<title>Jonathan Lindbloom - Auxiliary Magic</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Jonathan Lindbloom</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../research.html">Research</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../teaching.html">Teaching</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../software.html">Software</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#probabilistic-inverse-problems" id="toc-probabilistic-inverse-problems" class="nav-link active" data-scroll-target="#probabilistic-inverse-problems">Probabilistic Inverse Problems</a></li>
  <li><a href="#a-hierarchical-prior" id="toc-a-hierarchical-prior" class="nav-link" data-scroll-target="#a-hierarchical-prior">A Hierarchical Prior</a></li>
  <li><a href="#the-new-posterior" id="toc-the-new-posterior" class="nav-link" data-scroll-target="#the-new-posterior">The New Posterior</a></li>
  <li><a href="#an-inconvenience" id="toc-an-inconvenience" class="nav-link" data-scroll-target="#an-inconvenience">An Inconvenience</a></li>
  <li><a href="#an-auxiliary-variable-magic-trick" id="toc-an-auxiliary-variable-magic-trick" class="nav-link" data-scroll-target="#an-auxiliary-variable-magic-trick">An Auxiliary Variable Magic Trick</a></li>
  <li><a href="#the-augmented-hierarchical-model" id="toc-the-augmented-hierarchical-model" class="nav-link" data-scroll-target="#the-augmented-hierarchical-model">The Augmented Hierarchical Model</a></li>
  <li><a href="#the-code" id="toc-the-code" class="nav-link" data-scroll-target="#the-code">The Code</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Auxiliary Magic</h1>
</div>

<div>
  <div class="description">
    Hierarchical regularization via an auxiliary variable magic trick.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 12, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<p><a href="https://jlindbloom.github.io/posts/simple_image_deblurring.html">Last time</a> we looked at an image de-blurring problem, which we solved by finding</p>
<p><span id="eq-inv_prob_obj"><span class="math display">\[
x^\star = \text{argmin}_x \,\, \| A x - y \|_2^2 + \mathcal{R}(x)
\tag{1}\]</span></span></p>
<p>where the regularization term was</p>
<p><span class="math display">\[
\mathcal{R}(x) = \gamma \| L x \|_2^2 = \gamma x^T L^T L x.
\]</span></p>
<p>In this post, our goal is to: - describe a hierarchical prior and a method that can give us a better image reconstruction, - walk through a “magic” trick that will speed up our method, - and look at using <a href="https://cupy.dev/"><code>CuPy</code></a> to accelerate our reconstruction using a GPU.</p>
<section id="probabilistic-inverse-problems" class="level1">
<h1>Probabilistic Inverse Problems</h1>
<p>While the problem posed in <a href="#eq-inv_prob_obj">Equation&nbsp;1</a> is completely deterministic, we can actually think of it as haven arisen from a probabilistic model. Suppose that</p>
<p><span class="math display">\[
\begin{align*}
x &amp;\sim \mathcal{N}\left( 0, \left(\gamma L^T L \right)^{-1} \right), \\
y \, | \, x &amp;\sim \mathcal{N}\left( A x, I \right).
\end{align*}
\]</span></p>
<p>Then our corresponding density functions are</p>
<p><span class="math display">\[
\begin{align*}
\pi(x) &amp;\propto \exp\left\{ - \gamma x^T L^T L  x \right\}, \\
\pi(y \, | \, x) &amp;\propto \exp\left\{ - \| A x - y \|_2^2 \right\},
\end{align*}
\]</span></p>
<p>and by Bayes’ theorem the posterior density for <span class="math inline">\(x \, | \, y\)</span> is given as</p>
<p><span class="math display">\[
\pi(x \, | \, y) \propto \exp\left\{ - \| A x - y \|_2^2 \right\} \times \exp\left\{ - \gamma x^T L^T L  x \right\}.
\]</span></p>
<p>The <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">MAP estimate</a> of <span class="math inline">\(x\)</span> is then given as</p>
<p><span class="math display">\[
x^\star = \text{argmax}_x \,\, \pi(x \, | \, y),
\]</span></p>
<p>which is equivalent to</p>
<p><span class="math display">\[
\begin{align*}
x^\star &amp;= \text{argmin}_x \,\, - \log \pi(x \, | \, y) \\
&amp;= \text{argmin}_x \,\, \gamma \| L x \|_2^2 = \gamma x^T L^T L x,
\end{align*}
\]</span></p>
<p>which is exactly <a href="#eq-inv_prob_obj">Equation&nbsp;1</a>. The role of <span class="math inline">\(\mathcal{R}(x)\)</span> can then be seen as contributing a prior of</p>
<p><span class="math display">\[
\pi(x) \propto \exp\left\{ - \mathcal{R}(x) \right\}
\]</span></p>
<p>into the inference problem.</p>
</section>
<section id="a-hierarchical-prior" class="level1">
<h1>A Hierarchical Prior</h1>
<p>One reason it can be useful to think probabilistically is because we can motivate different choices of the regularizer <span class="math inline">\(\mathcal{R}(x)\)</span>. If we pick</p>
<p><span class="math display">\[
Lx \sim \mathcal{N}\left(0, \frac{1}{\gamma} I \right)
\]</span></p>
<p>as our prior (which corresponds to <span class="math inline">\(\mathcal{R}(x) = \gamma x^T L^T L x\)</span>), then we are saying that we believe that the discrete gradients in our image are distributed according to zero-mean Gaussian with variance <span class="math inline">\(\gamma^{-1}\)</span>. We can tweak the strength of the prior by adjusting <span class="math inline">\(\gamma\)</span> and in turn its influence on our reconstructed image, but note that the same <span class="math inline">\(\gamma\)</span> governs of the entire discrete gradient in the image. Thus we might think to introduce a hierarchical prior on the discrete gradient that could try to (loosely) capture the fact that in some regions in an image the discrete gradient will be much larger than it is elsewhere. Define the prior</p>
<p><span id="eq-hierarchical_prior"><span class="math display">\[
\begin{align*}
\beta^H_{i,j}, \beta^V_{i,j} &amp;\sim \Gamma \left( c, d \right), \\
L x &amp;\sim \mathcal{N} \left(0, B_{\beta} \right),
\end{align*}
\tag{2}\]</span></span></p>
<p>which has density</p>
<p><span class="math display">\[
\pi(x, \beta) = \pi(x \, | \, \beta) \pi(\beta) \propto \det \left( B_{\beta} \right)^{1/2} \exp\left\{ - x^T L^T B_{\beta} L x  \right\} \times \pi(\beta).
\]</span></p>
<p>Here <span class="math inline">\(\left( \cdot \right)^{V/H}\)</span> represent the fact that we are assigining two different hyper-parameter to govern the gradient in each the vertical and horizontal directions, <span class="math inline">\(\Gamma\left(c, d \right)\)</span> represents the <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma density function</a>,</p>
<p><span class="math display">\[
B_{\beta} = \text{diag}\left( \beta^V_{1,1}, \ldots, \beta^V_{m,n}, \beta^H_{1,1}, \ldots, \beta^H_{m,n} \right),
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\pi(\beta) \propto \left( \prod_{i,j}^{mn} \Gamma( \beta_{i,j}^H | c, d) \right) \times \left( \prod_{i,j}^{mn} \Gamma( \beta_{i,j}^V | c, d) \right)
\]</span></p>
<p>meaning that all hyper-parameters are assumed to be independent of one another. The reason we use a <span class="math inline">\(\Gamma\)</span> distribution for the hyper-parameter is because it is a <a href="https://en.wikipedia.org/wiki/Conjugate_prior">conjugate prior</a> for a Gaussian, meaning that we can determine certain relevant conditional distributions analytically.</p>
</section>
<section id="the-new-posterior" class="level1">
<h1>The New Posterior</h1>
<p>Using our prior <a href="#eq-hierarchical_prior">Equation&nbsp;2</a>, the full posterior in our original model (with an extra factor of <span class="math inline">\(\frac{1}{2}\)</span>, as well as a noise precision parameter <span class="math inline">\(\alpha\)</span>) is given as</p>
<p><span id="eq-hierarchical_posterior"><span class="math display">\[
\pi(x, \beta \, | \, y) \propto \exp\left\{ - \frac{\alpha}{2} \| A x - y \|_2^2 \right\} \times \det \left( B_{\beta} \right)^{1/2} \exp\left\{ - \frac{1}{2} x^T L^T B_{\beta} L x  \right\} \times \pi(\beta).
\tag{3}\]</span></span></p>
<p>In the sampling setting, a common approach that could be used to draw samples from this posterior is <a href="https://en.wikipedia.org/wiki/Gibbs_sampling">Gibbs sampling</a>, which involves iteratively drawing from the conditionals of each variable in the density given all of the others. In this case, our conditionals would be</p>
<p><span class="math display">\[
\begin{align*}
\pi(x \, | \, \beta, y) &amp;\propto \exp\left\{- \frac{\alpha}{2}\| A x - y \|_2^2 \right\} \times  \exp\left\{ - x^T L^T B_{\beta} L x  \right\}, \\
\pi(\beta \, | \, x, y) &amp;\propto \det \left( B_{\beta} \right)^{1/2} \exp\left\{ - x^T L^T B_{\beta} L x  \right\} \times \pi(\beta).
\end{align*}
\]</span></p>
<p>Due to conjugacy, we can recognize the first conditional to be a Gaussian and the second to be a Gamma distribution. Specifically, we have <span class="math inline">\(x \, | \, \beta, y \sim \mathcal{N}\left(\mu_1, Q_1^{-1} \right)\)</span> with</p>
<p><span class="math display">\[
\begin{align*}
Q_1 &amp;= \frac{1}{\alpha} A^T A + L^T B_{\beta} L, \\
\mu_1 &amp;= Q_1^{-1} \left( \frac{1}{\alpha} A^T y \right).
\end{align*}
\]</span></p>
<p>For <span class="math inline">\(\beta \, | \, x, y\)</span> we have</p>
<p><span class="math display">\[
\begin{align*}
\beta_{i,j} = \Gamma\left( \frac{1}{2} + c, \frac{1}{2}[L x]_{i,j}^2 + d \right),
\end{align*}
\]</span></p>
<p>where how you deal with <span class="math inline">\(\beta^V\)</span>/<span class="math inline">\(\beta^H\)</span> becomes clear when you think about the shapes of these operations.</p>
<p>Rather than code a Gibbs sampling algorithm, we will consider the (BCD) of <span class="citation" data-cites="Glaubitz2022">[<a href="#ref-Glaubitz2022" role="doc-biblioref">1</a>]</span>, which is essentially an optimization technique that iteratively draws from the mean of each the conditionals. We iterate</p>
<p><span class="math display">\[
\begin{align*}
x^{k+1} &amp;= \mathbb{E}_{\pi}\left( x \, | \, \beta^k, y \right), \\
\beta^{k+1} &amp;= \mathbb{E}_{\pi}\left( \beta \, | \, x^{k+1}, y \right),
\end{align*}
\]</span></p>
<p>until the solution converges. One thing to note is that we will generally not settle into a global minimum, since the posterior (with no restrictions on <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>) is not log-concave due to the use of a Gamma hyper-prior on the <span class="math inline">\(\beta_{i,j}\)</span>.</p>
</section>
<section id="an-inconvenience" class="level1">
<h1>An Inconvenience</h1>
<p>For the purposes of this post, we will assume that <span class="math inline">\(A\)</span> is a BCCB blurring matrix and that <span class="math inline">\(L\)</span> is an approximation to the discrete gradient with periodic boundary conditions such that <span class="math inline">\(L^T L\)</span> is also BCCB. These were the nice assumptions in the previous post that allowed us to reduce all of our linear system solves to FFTs/IFFs and diagonal matrix operations, as well as efficiently sample in the Fourier domain.</p>
<p>Note that while we have an analytic expression for the distribution <span class="math inline">\(x \, | \beta, y\)</span>, we can no longer use our BCCB assumptions to avoid linear system solves. Letting</p>
<p><span class="math display">\[
\begin{align*}
A &amp;= F^H \Lambda F, \\
L^T L &amp;= F^H \Pi F,
\end{align*}
\]</span></p>
<p>inserting this into <span class="math inline">\(Q_1^{-1} = \left( A^T A + L^T B_{\beta} L \right)^{-1}\)</span> we now get</p>
<p><span class="math display">\[
\begin{align*}
Q_1^{-1} &amp;= \left( \frac{1}{\alpha} A^T A +  L^T B_{\beta} L \right)^{-1} \\
&amp;= \left( \frac{1}{\alpha} F^H \Lambda F F^H \Lambda F +  L^T B_{\beta} L \right)^{-1} \\
&amp;= \left( \frac{1}{\alpha} F^H \Lambda^2 F +  L^T B_{\beta} L \right)^{-1}  \\
\end{align*}
\]</span></p>
<p>where unlike before we are now stuck. The problem is that <span class="math inline">\(B_{\beta}\)</span> is “sandwiched” in-between <span class="math inline">\(L^T\)</span> and <span class="math inline">\(L\)</span>, which prevents us from using the diagonalization of <span class="math inline">\(L^T L\)</span>. While it is not the end of the world to have to solve a linear system using a sparse solver or some other method, we still really would like to use the BCCB assumption to our advantage if we can.</p>
</section>
<section id="an-auxiliary-variable-magic-trick" class="level1">
<h1>An Auxiliary Variable Magic Trick</h1>
<p>It turns out there is a way to get around this, via a “magic trick” of <span class="citation" data-cites="Marnissi2018">[<a href="#ref-Marnissi2018" role="doc-biblioref">2</a>]</span>. I also discuss this in <a href="https://jlindbloom.github.io/posts/gaussian_posterior_formulas.html">this post</a> on Gaussian posterior formulas. For the moment let us fix <span class="math inline">\(B_{\beta}\)</span> to be a constant matrix. Out of the blue, define a new random variable via</p>
<p><span class="math display">\[
\begin{align*}
    u \, | \, x, y &amp;\sim \mathcal{N}\left( H x, Q^{-1}  \right),
\end{align*}
\]</span></p>
<p>where we are free to choose <span class="math inline">\(H\)</span> and <span class="math inline">\(Q\)</span> (as long as they define a valid distribution). Then, if we consider the joint density of <span class="math inline">\(u, x \, | \, y\)</span> we have that</p>
<p><span class="math display">\[
\begin{align*}
\pi(u, x \, | \, y) &amp;= \pi(u \, | \, x, y) \times \pi(x \, | \, y) \times \pi(x) \\
&amp;\propto \exp\left\{ -\frac{1}{2} \left( H x - u \right)^T Q \left( H x - u \right)  \right\} \times \exp\left\{ -\frac{1}{2} x^T L^T B L x  \right\} \times \pi(x \, | \, y) \\
&amp;\propto \exp\left\{ -\frac{1}{2} \left[ \left( H x - u \right)^T Q \left( H x - u \right) + x^T L^T B L x  \right] \right\} \times \pi(x \, | \, y) \\
&amp;\propto \exp\left\{ -\frac{1}{2} \left[ x^T H^T Q H x + u^T Q u - 2 x^T H^T Q u + x^T L^T B L x  \right] \right\} \times \pi(x \, | \, y) \\
&amp;\propto \exp\left\{ -\frac{1}{2} \left[ x^T P x + u^T Q u - 2 x^T H^T Q u  \right] \right\} \times \pi(x \, | \, y) \\
\end{align*}
\]</span></p>
<p>where we have defined</p>
<p><span class="math display">\[
P = H^T Q H + L^T B L.
\]</span></p>
<p>We are free to choose <span class="math inline">\(H\)</span> and <span class="math inline">\(Q\)</span>, so let’s make the magic choice</p>
<p><span class="math display">\[
\begin{align*}
H &amp;= L, \\
Q &amp;= \frac{1}{\lambda} I  - B.
\end{align*}
\]</span></p>
<p>Here <span class="math inline">\(\lambda &gt; 0\)</span> is a constant we are free to choose, so long as <span class="math inline">\(\lambda &lt; \frac{1}{\| B \|}\)</span> which makes <span class="math inline">\(Q\)</span> positive semi-definite as is required of a valid precision matrix. Inserting this choice <em>and conditioning on</em> <span class="math inline">\(u\)</span>, we obtain</p>
<p><span class="math display">\[
P = \frac{1}{\lambda} L^T L
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\begin{align*}
\pi(x \, | \, u,  y) &amp;\propto \exp\left\{ -\frac{1}{2} \left[ \frac{1}{\lambda} x^T L^T L x - 2 x^T L^T Q u  \right] \right\} \times \pi(x \, | \, y). \\
\end{align*}
\]</span></p>
<p>Now, we define yet another random variable</p>
<p><span class="math display">\[
v = Qu = \left( \frac{1}{\lambda} I  - B \right) u,
\]</span></p>
<p>insert into the density above to get</p>
<p><span class="math display">\[
\begin{align*}
\pi(x \, | \, v,  y) &amp;\propto \exp\left\{ -\frac{1}{2} \left[ \frac{1}{\lambda} x^T L^T L x - 2 x^T L^T v \right] \right\} \times \pi(x \, | \, y), \\
\end{align*}
\]</span></p>
<p>and finally complete the square in the exponential to finally arrive at</p>
<p><span class="math display">\[
\begin{align*}
\pi(x \, | \, v,  y) &amp;\propto \exp\left\{ -\frac{1}{2 \lambda} \| L x - \lambda v  \|_2^2  \right\} \times \pi(x \, | \, y), \\
\end{align*}
\]</span></p>
<p>which is the density of the Gaussian <span class="math inline">\(\mathcal{N}\left( \mu_2, Q_2^{-1} \right)\)</span> where</p>
<p><span class="math display">\[
\begin{align*}
Q_2 &amp;= \frac{1}{\lambda} L^T L + \frac{1}{\alpha} A^T A, \\
\mu_2 &amp;= Q_2^{-1} \left( \frac{1}{\alpha} A^T y +  L^T \left( \frac{1}{\lambda} I \right) \left( \lambda v \right)  \right) \\
&amp;= Q_2^{-1} \left( \frac{1}{\alpha} A^T y +  L^T  v \right).
\end{align*}
\]</span></p>
<p>Note that we could do this since the missing term in the square was independent of <span class="math inline">\(x\)</span>. Now we have what we wanted: <em>the matrix</em> <span class="math inline">\(B\)</span> <em>has disappeared</em> after conditioning on <span class="math inline">\(v\)</span>, and we can now take advantage of our BCCB assumption for this conditional. This is all only useful so long as the conditional distribution $v , | , x, y $ is also nice, which is the Gaussian <span class="math inline">\(\mathcal{N}\left( \mu_3, Q_3^{-1} \right)\)</span> where</p>
<p><span class="math display">\[
\begin{align*}
Q_3^{-1} &amp;= \frac{1}{\lambda} I - B, \\
\mu_3 &amp;= \left( \frac{1}{\lambda} I - B \right) L x,
\end{align*}
\]</span></p>
<p>which is nice to work with.</p>
</section>
<section id="the-augmented-hierarchical-model" class="level1">
<h1>The Augmented Hierarchical Model</h1>
<p>It turns out that when we allow <span class="math inline">\(B = B_{\beta}\)</span> to vary with hyper-parameters, everything we just did stays exactly the same, except we must choose a new <span class="math inline">\(\lambda= \lambda(B_{\beta})\)</span> such that <span class="math inline">\(\lambda &lt; \frac{1}{\| B_\beta \|}\)</span> for the current values of the hyper-parameters. We have already discussed the conditionals <span class="math inline">\(x \, | \, v, \beta, y\)</span> and <span class="math inline">\(v \, | \, x, \beta, y\)</span> which are the same as before, but it turns out that the conditional <span class="math inline">\(\beta \, | \, x, v, y\)</span> is not trivial. As far as I know, this conditional is no longer known directly. So is all of our work for nothing? Fortunately, no, due to a technique called partially collapsed Gibbs sampling (PCGS) <span class="citation" data-cites="vanDyk2008PartiallyCG">[<a href="#ref-vanDyk2008PartiallyCG" role="doc-biblioref">3</a>]</span>. Note that while we don’t know an analytic form for <span class="math inline">\(\beta \, | \, x, v, y\)</span>, we <em>do</em> know the form of <span class="math inline">\(\beta \, | \, x, y\)</span> which is the same as it was in the model before we introduced <span class="math inline">\(v\)</span>. PCGS is designed to take advantage of this by allowing us to only need access to <span class="math inline">\(\beta \, | \, x, y\)</span>, with the price being that the order in which we iterate through the conditionals now matters.</p>
<p>Thus our discussion leads us to a modified version of the BCD algorithm that uses an auxiliary variable to simplify the calculations for the update of each variable:</p>
<p><span class="math display">\[
\begin{align*}
x^{k+1} &amp;= \mathbb{E}_{\pi}\left( x \, | \, v^k, \beta^k, y \right), \\
v^{k+1} &amp;= \mathbb{E}_{\pi}\left( v \, | \, x^k, \beta^k, y \right), \\
\beta^{k+1} &amp;= \mathbb{E}_{\pi}\left( \beta \, | \, x^{k+1}, y \right).
\end{align*}
\]</span></p>
<p>We will test this out by building off our code from my <a href="https://jlindbloom.github.io/posts/simple_image_deblurring.html">previous post</a> on de-blurring.</p>
<!-- 
$\beta \, | \, x, v, y$ which has density

$$
\pi(\beta \, | \, x, v, y) \propto \exp\left\{ - \frac{1}{2} \left( v - B_{\beta} L x \right)^T B_{\beta}^{-1} \left( v - B_{\beta} L x \right) \right\} \times \det \left( B_{\beta} \right)^{1/2} \exp\left\{ - \frac{1}{2} x^T L^T B_{\beta} L x  \right\} \times \pi(\beta).
$$

However, we can determine this by just updating the gamma hyper-prior twice so that this conditional is -->
</section>
<section id="the-code" class="level1">
<h1>The Code</h1>
<p>The first thing we will do is some initial set-up for the problem such as setting up our differencing matrix and computing the diagonalizations of <span class="math inline">\(A\)</span> and <span class="math inline">\(L^T L\)</span>. We will use the same blurred image from the previous post.</p>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>capture</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse <span class="im">as</span> sp</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.ndimage <span class="im">import</span> gaussian_filter</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image, ImageOps</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load blurred image</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>blurred_img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="st">"blurred_grand_canyon.jpg"</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>blurred_img <span class="op">=</span> ImageOps.grayscale(blurred_img)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>blurred_img <span class="op">=</span> np.asarray(blurred_img)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>blurred_img <span class="op">=</span> blurred_img<span class="op">/</span><span class="dv">255</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>M, N <span class="op">=</span> blurred_img.shape</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Define blur operator using sigma</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>blur_sigma <span class="op">=</span> <span class="fl">20.0</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>blur_op <span class="op">=</span> <span class="kw">lambda</span> x: gaussian_filter(x, blur_sigma, mode<span class="op">=</span><span class="st">'wrap'</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute diagonalization for the blurring operator</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>rand_img <span class="op">=</span> np.random.randn(M,N)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>mat_prod_rand_img <span class="op">=</span> np.fft.fft2(blur_op(np.fft.ifft2(rand_img, norm<span class="op">=</span><span class="st">'ortho'</span>)), norm<span class="op">=</span><span class="st">'ortho'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> mat_prod_rand_img<span class="op">/</span>rand_img</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> np.real(lam) <span class="co"># We know it should be real</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>lam_inv <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>lam</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct our differencing matrices</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>d_mat_vert <span class="op">=</span> sp.eye(N)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>d_mat_vert.setdiag(<span class="op">-</span><span class="dv">1</span>,k<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>d_mat_vert <span class="op">=</span> sp.csc_matrix(d_mat_vert)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>d_mat_vert[<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="co"># For periodic BCs</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>eye_horiz <span class="op">=</span> sp.eye(M)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>d_mat_one <span class="op">=</span> sp.kron(eye_horiz, d_mat_vert)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>d_mat_horiz <span class="op">=</span> sp.eye(M)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>d_mat_horiz.setdiag(<span class="op">-</span><span class="dv">1</span>,k<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>d_mat_horiz <span class="op">=</span> sp.csc_matrix(d_mat_horiz)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>d_mat_horiz[<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="co"># For periodic BCs</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>eye_vert <span class="op">=</span> sp.eye(N)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>d_mat_two <span class="op">=</span> sp.kron(d_mat_horiz, eye_vert)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Make L, L^T, and L^T L</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>L <span class="op">=</span> sp.vstack([d_mat_one, d_mat_two])</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>Lt <span class="op">=</span> L.T</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>LtL <span class="op">=</span> Lt <span class="op">@</span> L </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Next, we need to compute $\Pi$ like we did earlier with $\Lambda$.</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>rand_img <span class="op">=</span> np.random.randn(M,N)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>mat_prod_rand_img <span class="op">=</span> np.fft.fft2( (LtL <span class="op">@</span> np.fft.ifft2(rand_img, norm<span class="op">=</span><span class="st">'ortho'</span>).flatten() ).reshape((M,N)), norm<span class="op">=</span><span class="st">'ortho'</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> mat_prod_rand_img<span class="op">/</span>rand_img</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> np.real(pi) <span class="co"># We know it should be real</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>pi_inv <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>pi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In order to quickly perform the FFTs/IFFTs needed for the algorithm, we will leverage a GPU via <a href="https://cupy.dev/"><code>CuPy</code></a>. I had previously tried doing this algorithm on CPUs with just NumPy alone and found that it took about one iteration per second, whereas with CuPy we can get about 500 iterations per 30 seconds (about 17 iterations per second).</p>
<p>In terms of NumPy vs.&nbsp;CuPy, the main things to keep in mind are that 1. you must explicitly transfer arrays between the CPU and GPU, and 2. while on the GPU, you must use functions that act on CuPy arrays.</p>
<p>Both of these are easy to do. For this post, I will suffix all arrays that live on the GPU with <code>_gpu</code>. Let’s bring all of the things we just computed onto the GPU:</p>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cupy <span class="im">as</span> cp</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Bring diagonalizations Pi and Lambda onto GPU</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>pi_gpu <span class="op">=</span> cp.asarray(pi)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>lam_gpu <span class="op">=</span> cp.asarray(lam)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Bring L, Lt, and LtL onto the GPU</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>L_gpu <span class="op">=</span> cp.sparse.csc_matrix(L)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>Lt_gpu <span class="op">=</span> cp.sparse.csc_matrix(Lt)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>LtL_gpu <span class="op">=</span> cp.sparse.csc_matrix(LtL)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that <a href="https://docs.scipy.org/doc/scipy/reference/sparse.html"><code>scipy.sparse</code></a> matrices are different from <a href="https://docs.cupy.dev/en/stable/reference/scipy_sparse.html"><code>cupy.sparse</code></a> matrices, and that we bring them onto the GPU by calling the CuPy constructor on the SciPy (CPU) version of the matrix.</p>
<p>To apply our blurring operator to a vector on the GPU, we will also need to use the CuPy version of <code>gaussian_filter</code>:</p>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cupyx.scipy.ndimage <span class="im">import</span> gaussian_filter <span class="im">as</span> cupy_gaussian_filter </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>blur_op_gpu <span class="op">=</span> <span class="kw">lambda</span> x: cupy_gaussian_filter(x, blur_sigma, mode<span class="op">=</span><span class="st">'wrap'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s make our arrays for <span class="math inline">\(x\)</span>, <span class="math inline">\(v\)</span>, <span class="math inline">\(y\)</span>, and <span class="math inline">\(\beta\)</span>:</p>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x_gpu <span class="op">=</span> cp.asarray(blurred_img) <span class="co"># Start x at the observed image</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>y_gpu <span class="op">=</span> cp.asarray(blurred_img) <span class="co"># The observation</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>v_gpu <span class="op">=</span> cp.asarray( L <span class="op">@</span> blurred_img.flatten() ) <span class="co"># Start v at Lx, this gives it the correct shape</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>betas_gpu <span class="op">=</span> <span class="dv">10</span><span class="op">*</span>cp.ones(<span class="dv">2</span><span class="op">*</span>M<span class="op">*</span>N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Remember that we need to pick a new value of <span class="math inline">\(\lambda\)</span> each time we update <span class="math inline">\(\beta\)</span>. We will make the choice</p>
<p><span class="math display">\[
\lambda(\beta) = \frac{1}{2}\left( \frac{1}{\| B_{\beta} \|} + 0\right),
\]</span></p>
<p>which should be half of the maximum value we would be allowed to pick for <span class="math inline">\(\lambda\)</span>. I am not sure how picking <span class="math inline">\(\lambda\)</span> on the high or low side affects the performance, but I would guess that higher is better. In our code, I will refer to this <span class="math inline">\(\lambda\)</span> as <code>lam_aux</code>.</p>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>lam_aux <span class="op">=</span> ((<span class="dv">1</span><span class="op">/</span>cp.amax(betas_gpu)) <span class="op">+</span> <span class="dv">0</span>)<span class="op">/</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We also need to set some noise precision <span class="math inline">\(\alpha = \sigma^{-2}\)</span>, and we can go ahead and pre-compute <span class="math inline">\(\frac{1}{\alpha} A^T y\)</span> which shows up in our formula for the conditional for <span class="math inline">\(x\)</span>.</p>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>noise_sigma <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>noise_prec <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(noise_sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>Aty_gpu <span class="op">=</span> noise_prec<span class="op">*</span>blur_op_gpu(y_gpu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And finally, we must select the hyper-hyper-parametes <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>. We will examine two choices, the first being the “uniformative” choice</p>
<p><span class="math display">\[
\begin{align*}
c &amp;= 1.0, \\
d &amp;= 10^{-20},
\end{align*}
\]</span></p>
<p>which corresponds to a flat prior.</p>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="fl">1e-20</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now we are ready to perform the BCD algorithm for the reconstruction of <span class="math inline">\(x\)</span> from <span class="math inline">\(y\)</span>. I will not go into the details, as all of the operations are just the implementation of the steps we outlined earlier.</p>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastprogress <span class="im">import</span> progress_bar</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set some number of iterations</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Now do BCD</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> progress_bar(<span class="bu">range</span>(n_iterations)):</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update x</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    Ltv_gpu <span class="op">=</span> ( Lt_gpu <span class="op">@</span> v_gpu ).reshape((M,N))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> Aty_gpu <span class="op">+</span> Ltv_gpu</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    mu_x <span class="op">=</span> cp.fft.fft2( b, norm<span class="op">=</span><span class="st">'ortho'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    diag_fourier_vec <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>( (<span class="dv">1</span><span class="op">/</span>lam_aux)<span class="op">*</span>(pi_gpu) <span class="op">+</span> (noise_prec)<span class="op">*</span>(lam_gpu<span class="op">**</span><span class="dv">2</span>) )</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    mu_x <span class="op">=</span> diag_fourier_vec<span class="op">*</span>mu_x</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    mu_x <span class="op">=</span> cp.real(cp.fft.ifft2(mu_x, norm<span class="op">=</span><span class="st">'ortho'</span>))</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    x_gpu <span class="op">=</span> mu_x</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update betas</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    gamma_alpha <span class="op">=</span> c <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    gamma_beta <span class="op">=</span> <span class="fl">0.5</span><span class="op">*</span>( ( L_gpu <span class="op">@</span> x_gpu.flatten() )<span class="op">**</span><span class="dv">2</span>) <span class="op">+</span> d </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    betas_gpu <span class="op">=</span> gamma_alpha<span class="op">/</span>gamma_beta</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update lam_aux</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    lam_aux <span class="op">=</span> ( (<span class="dv">1</span><span class="op">/</span>cp.amax(betas_gpu) ) <span class="op">+</span> <span class="dv">0</span>)<span class="op">/</span><span class="dv">2</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make sure that this is always true</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.<span class="bu">all</span>((<span class="dv">1</span><span class="op">/</span>lam_aux) <span class="op">-</span> betas_gpu <span class="op">&gt;</span> <span class="dv">0</span>), <span class="st">"invalid choice of lam_aux was made"</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update v</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    v_gpu <span class="op">=</span> ( (<span class="dv">1</span><span class="op">/</span>lam_aux) <span class="op">-</span> betas_gpu )<span class="op">*</span>( L_gpu <span class="op">@</span> x_gpu.flatten() )</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Bring arrays back to the cpu</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> cp.asnumpy(x_gpu)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> cp.asnumpy(v_gpu)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>betas <span class="op">=</span> cp.asnumpy(betas_gpu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value="500" class="" max="500" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [500/500 00:29&lt;00:00]
    </div>
    
</div>
</div>
<p>Let’s look at the reconstruction, as well as <span class="math inline">\(\beta\)</span>. Here I have plotted the <code>betas</code> on an inverse scale, so brighter pixels should correspond to a higher variance parameter. I have also artificially clipped the array to its 95th percentile, since there are some extremely large precision values that make the entire plot monotone.</p>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'axes.facecolor'</span>] <span class="op">=</span> <span class="st">'#0F2537'</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'text.color'</span>] <span class="op">=</span> <span class="st">'white'</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'axes.labelcolor'</span>] <span class="op">=</span> <span class="st">'white'</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'xtick.color'</span>] <span class="op">=</span> <span class="st">'white'</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'ytick.color'</span>] <span class="op">=</span> <span class="st">'white'</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>plot_name <span class="op">=</span> <span class="st">"uninformative_prior"</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plot_which <span class="op">=</span> <span class="st">"Uniformative prior"</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">13</span>))</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.real(x), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>plt.title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"BCD reconstruction"</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>betas <span class="op">=</span> betas.reshape((<span class="dv">2</span>,M,N))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>betas_one, betas_two <span class="op">=</span> betas[<span class="dv">0</span>,:,:], betas[<span class="dv">1</span>,:,:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">13</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.clip(betas_one, a_min<span class="op">=</span><span class="va">None</span>, a_max <span class="op">=</span> np.quantile(betas_one.flatten(), <span class="fl">0.95</span>)), cmap<span class="op">=</span><span class="st">'Greens_r'</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"betas (horizontal)"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">13</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.clip(betas_two, a_min<span class="op">=</span><span class="va">None</span>, a_max <span class="op">=</span> np.quantile(betas_two.flatten(), <span class="fl">0.95</span>)), cmap<span class="op">=</span><span class="st">'Greens_r'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"betas (vertical)"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Notice how you can (somewhat) trace out some of the edges in the image by the inferred variance parameters. Here is a comparison of the original, blurred, and reconstructed images:</p>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load original image</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="st">"grand_canyon.jpg"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> ImageOps.grayscale(img)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> np.asarray(img)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img<span class="op">/</span><span class="dv">255</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">26</span>,<span class="dv">26</span>))</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].imshow(img, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">"Original image"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].imshow(np.real(x), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"BCD reconstruction"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">2</span>].imshow(blurred_img, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">2</span>].set_title(<span class="st">"Blurred image"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The last thing I will point out is that by changing the <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span> hyper-hyper-parameters, you can change the degree of sparsity in the prior on <span class="math inline">\(L x\)</span>. As we did in a <a href="https://jlindbloom.github.io/posts/hierarchical_cmrf.html">previous post</a>, we can recover a prior that is marginally Cauchy with a special choice of <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>. Let’s repeat the reconstruction with the choice</p>
<p><span class="math display">\[
\begin{align*}
c &amp;= 0.5, \\
d &amp;= 0.5(0.0005^2).
\end{align*}
\]</span></p>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>noise_sigma <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="fl">0.5</span><span class="op">*</span>(<span class="fl">0.0005</span><span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>x_gpu <span class="op">=</span> cp.asarray(blurred_img) <span class="co"># Start x at the observed image</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>y_gpu <span class="op">=</span> cp.asarray(blurred_img) <span class="co"># The observation</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>v_gpu <span class="op">=</span> cp.asarray( L <span class="op">@</span> blurred_img.flatten() ) <span class="co"># Start v at Lx, this gives it the correct shape</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>betas_gpu <span class="op">=</span> <span class="dv">10</span><span class="op">*</span>cp.ones(<span class="dv">2</span><span class="op">*</span>M<span class="op">*</span>N)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>lam_aux <span class="op">=</span> ((<span class="dv">1</span><span class="op">/</span>cp.amax(betas_gpu)) <span class="op">+</span> <span class="dv">0</span>)<span class="op">/</span><span class="dv">2</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>noise_prec <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(noise_sigma<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>Aty_gpu <span class="op">=</span> noise_prec<span class="op">*</span>blur_op_gpu(y_gpu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set some number of iterations</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>n_iterations <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Now do BCD</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> progress_bar(<span class="bu">range</span>(n_iterations)):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update x</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    Ltv_gpu <span class="op">=</span> ( Lt_gpu <span class="op">@</span> v_gpu ).reshape((M,N))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> Aty_gpu <span class="op">+</span> Ltv_gpu</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    mu_x <span class="op">=</span> cp.fft.fft2( b, norm<span class="op">=</span><span class="st">'ortho'</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    diag_fourier_vec <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>( (<span class="dv">1</span><span class="op">/</span>lam_aux)<span class="op">*</span>(pi_gpu) <span class="op">+</span> (noise_prec)<span class="op">*</span>(lam_gpu<span class="op">**</span><span class="dv">2</span>) )</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    mu_x <span class="op">=</span> diag_fourier_vec<span class="op">*</span>mu_x</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    mu_x <span class="op">=</span> cp.real(cp.fft.ifft2(mu_x, norm<span class="op">=</span><span class="st">'ortho'</span>))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    x_gpu <span class="op">=</span> mu_x</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update betas</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    gamma_alpha <span class="op">=</span> c <span class="op">+</span> <span class="fl">0.5</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    gamma_beta <span class="op">=</span> <span class="fl">0.5</span><span class="op">*</span>( ( L_gpu <span class="op">@</span> x_gpu.flatten() )<span class="op">**</span><span class="dv">2</span>) <span class="op">+</span> d </span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    betas_gpu <span class="op">=</span> gamma_alpha<span class="op">/</span>gamma_beta</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update lam_aux</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    lam_aux <span class="op">=</span> ( (<span class="dv">1</span><span class="op">/</span>cp.amax(betas_gpu) ) <span class="op">+</span> <span class="dv">0</span>)<span class="op">/</span><span class="dv">2</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make sure that this is always true</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> np.<span class="bu">all</span>((<span class="dv">1</span><span class="op">/</span>lam_aux) <span class="op">-</span> betas_gpu <span class="op">&gt;</span> <span class="dv">0</span>), <span class="st">"invalid choice of lam_aux was made"</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">### Update v</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    v_gpu <span class="op">=</span> ( (<span class="dv">1</span><span class="op">/</span>lam_aux) <span class="op">-</span> betas_gpu )<span class="op">*</span>( L_gpu <span class="op">@</span> x_gpu.flatten() )</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Bring arrays back to the cpu</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> cp.asnumpy(x_gpu)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> cp.asnumpy(v_gpu)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>betas <span class="op">=</span> cp.asnumpy(betas_gpu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value="500" class="" max="500" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [500/500 00:29&lt;00:00]
    </div>
    
</div>
</div>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plot_name <span class="op">=</span> <span class="st">"strong_cauchy_prior"</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>plot_which <span class="op">=</span> <span class="st">"Strong Cauchy prior"</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">13</span>))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.real(x), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"BCD reconstruction"</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>betas <span class="op">=</span> betas.reshape((<span class="dv">2</span>,M,N))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>betas_one, betas_two <span class="op">=</span> betas[<span class="dv">0</span>,:,:], betas[<span class="dv">1</span>,:,:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">13</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.clip(betas_one, a_min<span class="op">=</span><span class="va">None</span>, a_max <span class="op">=</span> np.quantile(betas_one.flatten(), <span class="fl">0.95</span>)), cmap<span class="op">=</span><span class="st">'Greens'</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"betas (horizontal)"</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">13</span>))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.clip(betas_two, a_min<span class="op">=</span><span class="va">None</span>, a_max <span class="op">=</span> np.quantile(betas_two.flatten(), <span class="fl">0.95</span>)), cmap<span class="op">=</span><span class="st">'Greens'</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"betas (vertical)"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">26</span>,<span class="dv">26</span>))</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].imshow(img, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">"Original image"</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].imshow(np.real(x), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(plot_which <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">"BCD reconstruction"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">2</span>].imshow(blurred_img, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">2</span>].set_title(<span class="st">"Blurred image"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="auxiliary_magic_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-Glaubitz2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline"><span class="smallcaps">Glaubitz</span>, J., <span class="smallcaps">Gelb</span>, A. and <span class="smallcaps">Song</span>, G. (2022). <a href="https://doi.org/10.48550/ARXIV.2201.07061">Generalized sparse bayesian learning and application to image reconstruction</a>.</div>
</div>
<div id="ref-Marnissi2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline"><span class="smallcaps">Marnissi</span>, Y., <span class="smallcaps">Chouzenoux</span>, E., <span class="smallcaps">Benazza-Benyahia</span>, A. and <span class="smallcaps">Pesquet</span>, J.-C. (2018). <a href="https://doi.org/10.3390/e20020110">An auxiliary variable method for markov chain monte carlo algorithms in high dimension</a>. <em>Entropy</em> <strong>20</strong>.</div>
</div>
<div id="ref-vanDyk2008PartiallyCG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline"><span class="smallcaps">Dyk</span>, D. A. van and <span class="smallcaps">Park</span>, T. (2008). Partially collapsed gibbs samplers. <em>Journal of the American Statistical Association</em> <strong>103</strong> 790–6.</div>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>